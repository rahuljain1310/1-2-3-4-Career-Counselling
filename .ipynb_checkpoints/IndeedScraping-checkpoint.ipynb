{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-0c4c4b2f8d26>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mparam1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mparam2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mparam3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;31m#param4 = sys.argv[4]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m#param5 = sys.argv[5]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import time\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import sys\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "param1 = \"Machine Learning\"\n",
    "param2 = \"Delhi\"\n",
    "param3 = \"4\"\n",
    "#param4 = sys.argv[4]\n",
    "#param5 = sys.argv[5]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "options = webdriver.ChromeOptions()#\"\n",
    "prefs={\"profile.managed_default_content_settings.images\": 2,'disk-cache-size': 4096 }\n",
    "options.add_experimental_option('prefs', prefs)\n",
    "options.headless = True\n",
    "#options.add_argument(\"user-data-dir=/Users/manthan/Library/Application Support/Google/Chrome\")\n",
    "#chrome_options.add_argument(\"--incognito\")\n",
    "options.add_argument('disable-infobars')\n",
    "driver = webdriver.Chrome(executable_path='chromedriver', chrome_options=options)\n",
    "url = 'https://resumes.indeed.com/search?q=' + str(param1) + '&l=' + str(param2) + '&searchFields=jt'\n",
    "url2 = 'https://resumes.indeed.com/'\n",
    "url3 = 'https://www.indeed.co.in/jobs?q=C&l=Delhi'\n",
    "url4 = 'https://www.indeed.co.in/' + str(param1) + '-jobs-in-' + str(param2)\n",
    "#url7 = 'https://www.indeed.co.in/jobs?q=' + str(param1) + '&l=' + str(param2) + '&start=' + str(param4) + '0'\n",
    "#url8 = 'https://www.indeed.co.in/jobs?q=' + str(param1) + '&l=' + str(param2) + '&start=' + str(param5) + '0'\n",
    "#print(url6)\n",
    "url5 = 'https://www.indeed.co.in/pagead/clk?mo=r&ad=-6NYlbfkN0DFi1nmQQWK2fa3N4W3y7EUOEocZkWPqKP_f_xZ7ne8RVZdLh4RDnCtsmh0Chq7FaNdqHt2-vbaxalNkFsI6khPoTCzfC4oTx5EJikL9Sdx-HULx2ykO3Kmqe5RDp0e6faggJKv9m7yZ0vJcoPs5dtaxnNRCwMJUeADuBlhrOE1fdh3u6rVLylTncEl4srX9r2I-GEOmE7jRrYFcsaurQsqzUoGo41uyrTqx5Fy2-5Uw0ydoGs7VB7oFFgzoJAZarJCujsEo5nx4613cvaLfOSiAJ9_Pg7Mi5kH3QteYlhDUm_remW8Sxk22-zLH7HPIDoI6fiGDtog-ERXlyvSwd5WfpKPS7PNIoITRNYxd7YiyyIR3nrHviCPCNe4E02jugdTgZB_G0p9jmZjDLEeaaCxAzfPYzM8TVmUWUneXf545HEEy1mhmFEknic7KsBUxZz-2LHyd5RqrMFuNT4TilGXYSVqDJbzF6hHIpiOuSq6LaC2gRJFgRkdhJfpmuSMRYmp9HPQSUi_Yrl1WVvo-dIWsh_k_nkfOHHkpGSHltVfmhV2wJzAAiUNWSFghZ3vu0SitDK88qmxAgnrtFZy1-QNvCWd9w9bX8OCZOICUUzN6bXf2a5M7UARRWlFv7CowOkeCgGm1BzeRxPKdxymdoHG&atk='\n",
    "\n",
    "\n",
    "\n",
    "#data = []\n",
    "#name= []\n",
    "#location = []\n",
    "#com = []\n",
    "#descr = []\n",
    "def frontpage2(link1):\n",
    "    data = []\n",
    "    name= []\n",
    "    location = []\n",
    "    com = []\n",
    "    descr = []\n",
    "    driver.get(link1)\n",
    "    about_page=driver.page_source\n",
    "    abt_soup = bs(about_page, \"html.parser\")\n",
    "    heading = abt_soup.find('h3')\n",
    "    print(heading.text)\n",
    "    loc=abt_soup.find('span',{'class':'jobsearch-JobMetadataHeader-iconLabel'})\n",
    "    print(loc.text)\n",
    "    exp=abt_soup.find('span',{'class':'jobsearch-JobMetadataHeader-iconLabel'})\n",
    "    print(exp.text)\n",
    "    company = abt_soup.find(\"div\", attrs = {'class':'icl-u-lg-mr--sm icl-u-xs-mr--xs'})\n",
    "    print(company.text)\n",
    "    desc = abt_soup.find(\"div\", attrs = {'class':'jobsearch-jobDescriptionText'})\n",
    "    print(desc.text)\n",
    "    print(\"------------------------\")\n",
    "#    name = heading.text\n",
    "#    location = loc.text\n",
    "#    com = company.text\n",
    "#    descr = desc.text\n",
    "    name.append(heading.text)\n",
    "    location.append(loc.text)\n",
    "    com.append(company.text)\n",
    "    descr.append(desc.text)\n",
    "    #df = pd.DataFrame({'name': [name], 'location': [location], 'company': [com] , 'description' : [desc]})\n",
    "    temp = pd.DataFrame({'Name':name, 'Location': location, 'Company': com, 'Description': descr})\n",
    "    temp.to_csv(param1 + '.csv', mode = 'a', header = True , index = False)\n",
    "#    with open(company.text + '.csv','xt') as content:\n",
    "#        content.write(heading.text)\n",
    "#        #content.write('\\n')\n",
    "#        content.write(loc.text)\n",
    "#        #content.write('\\n')\n",
    "#        content.write(desc.text)\n",
    "#content.write('\\n')\n",
    "\n",
    "\n",
    "def frontpage(ur):\n",
    "    driver.get(ur)\n",
    "    page_source=driver.page_source\n",
    "    soup = bs(page_source, \"html.parser\")\n",
    "    for link in soup.findAll(\"a\", {\"class\": \"jobtitle\"}):\n",
    "        dp_link=link.get('href')\n",
    "        check = dp_link.split(\":\")\n",
    "        print(check[0])\n",
    "        if check[0]=='https':\n",
    "            frontpage2(dp_link)\n",
    "        else:\n",
    "            full_url = \"https://www.indeed.co.in\" + dp_link\n",
    "            frontpage2(full_url)\n",
    "\n",
    "#temp = pd.DataFrame({'Name':name, 'Location': location, 'Company': com, 'Description': descr})\n",
    "#temp.to_csv(param1 + '.csv', mode = 'a', header = True , index = False)\n",
    "\n",
    "d = int(param3)\n",
    "    \n",
    "for i in range(d):\n",
    "    url6 = 'https://www.indeed.co.in/jobs?q=' + str(param1) + '&l=' + str(param2) + '&start=' +  str(i) + '0'\n",
    "    frontpage(url6)\n",
    "    print(i)\n",
    "\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
