{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import re\n",
    "import math\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import csv,sys,time\n",
    "\n",
    "# ntlk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "from nltk.probability import FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating list of all Career\n",
    "CareerTypes = [\"Machine Learning\"\n",
    "               ,\"Artificial Intelligence\"\n",
    "               ,\"Deep Learning\"\n",
    "               ,\"Android Developement\"\n",
    "               ,\"Web Development\"\n",
    "               ,\"Database Management\"\n",
    "#                ,\"Consultancy\"\n",
    "               ,\"Finance\"\n",
    "#                ,\"Neural Network\"\n",
    "#                ,\"Convolutions\"\n",
    "#                ,\"Data Science\"\n",
    "#                ,\"Business Analyst\"\n",
    "#                ,\"IOT\"\n",
    "               ,\"Programming\"\n",
    "#                ,\"Designing\"\n",
    "#                ,\"Mechanical Engineering\"\n",
    "#                ,\"Electrical Engineering\"\n",
    "#                ,\"Civil Engineering\"\n",
    "#                ,\"Chemical Engineering\"\n",
    "               ,\"Software Developer\"\n",
    "               ,\"Game Developer\"\n",
    "               ,\"Backend Developer\"\n",
    "               ,\"Frontend Developer\"\n",
    "              ]\n",
    "\n",
    "# Creating list of all Skills\n",
    "SkillTypes = [\"R\",\n",
    "              \"C++\",\n",
    "              \"C\",\n",
    "              \"Python\",\n",
    "              \"Java\",\n",
    "              \"R\",\n",
    "              \"Tensorflow\",\n",
    "              \"Keraz\",\n",
    "#               \"RNN\",\n",
    "#               \"CNN\",\n",
    "#               \"SVM\",\n",
    "#               \"Unity\",\n",
    "              \"Android Studio\",\n",
    "              \"Photoshop\",\n",
    "              \"Arduino\",\n",
    "#               \"Rasberry\",\n",
    "#               \"FPGA\",\n",
    "#               \"Chemical\",\n",
    "#               \"Economics\",\n",
    "#               \"Accounting\",\n",
    "#               \"Postgres\",\n",
    "              \"React\",\n",
    "              \"PhP\",\n",
    "              \"HTML\",\n",
    "              \"CSS\",\n",
    "              \"NodeJs\",\n",
    "#               \"Debating\",\n",
    "#               \"Tableau\",\n",
    "              \"Analog\",\n",
    "#               \"NgSpice\",\n",
    "#               \"Neural Network\"\n",
    "              ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanitize_input(data):\n",
    "    replace = {\n",
    "        ord('\\f') : ' ', \n",
    "        ord('\\t') : ' ',\n",
    "        ord('\\n') : ' ',\n",
    "        ord('\\r') : None\n",
    "    }\n",
    "    return data.translate(replace)\n",
    "\n",
    "def remove_html_tags(text):\n",
    "    \"\"\"Remove html tags from a string\"\"\"\n",
    "    import re\n",
    "    clean = re.compile('<.*?>')\n",
    "    return re.sub(clean, '', text)\n",
    "\n",
    "def tokenize_content(content):\n",
    "    stop_words = set(stopwords.words('english') + list(punctuation))\n",
    "    words = word_tokenize(content.lower())\n",
    "    return [word for word in words if word not in stop_words]\n",
    "\n",
    "def word_freq(content):\n",
    "    filtered_words = tokenize_content(content)\n",
    "    word_freq = FreqDist(filtered_words)\n",
    "    return word_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "All_Resume = {}\n",
    "TotalResumes = 0\n",
    "\n",
    "#### Settings #### \n",
    "options = webdriver.ChromeOptions()\n",
    "prefs={\"profile.managed_default_content_settings.images\": 2,'disk-cache-size': 4096 }\n",
    "options.add_experimental_option('prefs', prefs)\n",
    "options.headless = True\n",
    "#options.add_argument(\"user-data-dir=/Users/manthan/Library/Application Support/Google/Chrome\")\n",
    "#chrome_options.add_argument(\"--incognito\")\n",
    "options.add_argument('disable-infobars')\n",
    "driver = webdriver.Chrome(executable_path='chromedriver', options=options)\n",
    "\n",
    "def frontpage2(arr, link1):\n",
    "    driver.get(link1)\n",
    "    about_page = driver.page_source    \n",
    "    abt_soup = bs(about_page, \"html.parser\")\n",
    "    \n",
    "    ## Find Text\n",
    "    heading = abt_soup.find('h3').text\n",
    "    desc = abt_soup.find(\"div\", attrs = {'class':'jobsearch-jobDescriptionText'}).text\n",
    "#     loc=abt_soup.find('span',{'class':'jobsearch-JobMetadataHeader-iconLabel'})\n",
    "#     exp=abt_soup.find('span',{'class':'jobsearch-JobMetadataHeader-iconLabel'})\n",
    "#     company = abt_soup.find(\"div\", attrs = {'class':'icl-u-lg-mr--sm icl-u-xs-mr--xs'})    \n",
    "    JobDescriptionText = sanitize_input(heading+\" \"+desc)\n",
    "    JobDescriptionText = \" \".join(tokenize_content(JobDescriptionText))\n",
    "    arr.append(JobDescriptionText)\n",
    "    \n",
    "def frontpage(All_Resume, career,ResumesUrl):\n",
    "    JD = []\n",
    "    driver.get(ResumesUrl)\n",
    "    page_source=driver.page_source\n",
    "    soup = bs(page_source, \"html.parser\")\n",
    "    for link in soup.findAll(\"a\", {\"class\": \"jobtitle\"}):\n",
    "        dp_link = link.get('href')\n",
    "        if dp_link.split(\":\")[0]=='https':\n",
    "            frontpage2(JD,dp_link)\n",
    "        else:\n",
    "            frontpage2(JD,\"https://www.indeed.co.in\" + dp_link)\n",
    "    All_Resume[career] = JD\n",
    "\n",
    "for career in CareerTypes:\n",
    "    for i in range(5):\n",
    "        frontpage(All_Resume, career,'https://www.indeed.co.in/jobs?q='+career+'&start='+str(i)+'0')\n",
    "        TotalResumes += len(All_Resume[career])\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def termFrequency (skill, skill_resume):\n",
    "    i = 0.0;\n",
    "    for c in skill_resume:\n",
    "        cmt = c.count(skill)\n",
    "        if(cmt>0):\n",
    "            i+=1.0\n",
    "    total_resume = len(skill_resume)\n",
    "    try:\n",
    "        termFrequency = i/total_resume\n",
    "    except:\n",
    "        termFrequency = 0\n",
    "    return termFrequency\n",
    "def SkillCountInSkill(job, job_resumes):\n",
    "    count = 0\n",
    "    for x in job_resumes:\n",
    "        if(x.count(job)>0):\n",
    "            count+=1\n",
    "    return count\n",
    "def idf (job, all_resumes):\n",
    "    N = TotalResumes\n",
    "    nw = 1\n",
    "    for skill_resume in all_resumes:\n",
    "        nw += SkillCountInSkill(job,skill_resume)\n",
    "    idf = math.log(N/(nw+1))\n",
    "    return idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculates P(i/j)\n",
    "def relevance(i,j):\n",
    "    return idf(i.lower(),All_Resume)*termFrequency(i.lower(),All_Resume[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculating Career Skill Matrix:\n",
    "## find relevence of a page on the basis of query \n",
    "CareerSkillMatrix = []\n",
    "for j in CareerTypes:\n",
    "    y = [relevance(i,j) for i in SkillTypes ]\n",
    "    CareerSkillMatrix.append(y)\n",
    "print(CareerSkillMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SkillCount(x,text):\n",
    "    res = text.count(x.lower())\n",
    "    return (1 if res > 0 else 0)\n",
    "def BoolSkillMatrix(text):\n",
    "    BoolSkillMatrixJD = [SkillCount(x,text) for x in SkillTypes]\n",
    "    return np.array([BoolSkillMatrixJD])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculating Skill Skill Matrix:\n",
    "s = len(SkillTypes)\n",
    "SkillMatrix_JD = np.zeros((s,s))\n",
    "for career in CareerTypes:\n",
    "    for jd in All_Resume[career]:\n",
    "        X = BoolSkillMatrix(jd)\n",
    "        X = X.T.dot(X)\n",
    "        SkillMatrix_JD += X\n",
    "print(SkillMatrix_JD)\n",
    "maxE = SkillMatrix_JD.max(axis=0)\n",
    "SkillMatrix_JD = (SkillMatrix_JD.T)/maxE\n",
    "SkillMatrix_JD = SkillMatrix_JD.T\n",
    "print(SkillMatrix_JD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Finding The User Skill Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getUserSkillMatrix(CV):\n",
    "    UserSkillArr = BoolSkillMatrix(CV)\n",
    "    x = np.argwhere(UserSkillArr==1)\n",
    "    SkillMatrix = SkillMatrix_JD[x[:,1],:]\n",
    "    return SkillMatrix.max(axis=0)\n",
    "def getJobDescriptionSkillMatrix(JD):\n",
    "    BoolSkillMatrixJD = BoolSkillMatrix(JD)\n",
    "    return BoolSkillMatrixJD\n",
    "def SimilaritySkillMatrix(M1,M2):\n",
    "    return (M1.dot(M2.T))/math.sqrt(( np.sum(M1**2) * np.sum(M2**2) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "JD = (\"Deep Learning Engineer Deep Learning Engineer Bengaluru, Karnataka To gain employment with a company that offers me consistently positive atmosphere to learn new technologies and implement them for the betterment of the business.\"\n",
    "     \"Work Experience Deep Learning Engineer DronaMaps Pvt Ltd June 2018 to May 2019 Gurugram Currently, I am working on aerial images which are taken from drones for processing those images in useful result by applying deep learning and image processing techniques.\"\n",
    "     \"Industrial Projects • Building footprint detection from aerial images of drone - Use CNN (U-NET) to apply semantic segmentation on aerial images to find the footprint of building. • Road detection from aerial images of drone - Use CNN (U-NET) to apply semantic \"\n",
    "     \"gmentation on aerial images to find the road. • Building type classification from aerial images of drone - Classify building in four different class in aerial drone images using CNN (Dense Net) • Crop classification based on drone aerial images - To classify crops\"\n",
    "     \"drone aerial images using CNN • Plant stress detection - Apply Kernel method on aerial images for identification of plant stress. - Use Neural Network for finding plant stress from aerial image Capturing from drone and creating dataset. • Plant population count\"\n",
    "     \"ed Convolutions Neural Network (CNN) to counting plant from aerial images of drone. • Depth estimation from RGB images using Deep Learning for Indoor Mapping - RGBD Salient Object Detection data set used to train CNN model for esti- mation depth map of RGB images.\"\n",
    "     \"Aerial image classification   Data set is created in hdf5 format, which contains usable images and un- usable images for data processing. CNN is used for classify usable images • 3D Reconstruction using Aerial Drone Images - Data acquisition using drone and process \"\n",
    "     \"on Open Drone Maps. • Point Cloud Classification - In the process of 3D reconstruction point cloud is generated. Deep Learning model (Point-Net) is used on point cloud for point cloud classification. NEURAL (Less than 1 year), NEURAL NETWORK (Less than 1 year), \"\n",
    "     \"DEEP LEARNING ss than 1 year), ESTIMATION (Less than 1 year), SEGMENTATION (Less than 1 year) https://github.com/Shahzadnit Additional Information Technical Proficiency Computer Vision: Classification, Regression, Semantic Segmentation, Depth estimation \"\n",
    "     \"ep Learning Convolutional Neural Network, Auto-encoder, GAN Machine Learning Neural Network, SVM Mathematics Optimization, Backpropogation of Neural Network General Programming C, C++, Python, OpenCV-python, PyTorch, MATLAB, LaTeX\")\n",
    "JD = RefineText(JD).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "## Finding Similarity Score between User Skill Matrix and Job Description Skill Matrix## Finding the Job Description Skill Matrix\n",
    "UserSkillMatrix = getUserSkillMatrix(JD)\n",
    "JDSkillMatrixBool = getJobDescriptionSkillMatrix(JD)\n",
    "RelevenceOfUserSkill = JDSkillMatrixBool*UserSkillMatrix\n",
    "Score = SimilaritySkillMatrix(RelevenceOfUserSkill,JDSkillMatrixBool)[0][0]\n",
    "print(Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
